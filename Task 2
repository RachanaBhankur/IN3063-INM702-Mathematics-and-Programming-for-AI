
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f33d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import math as m\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fcca640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    #Implements the sigmoid activation in numpy#\n",
    "    \n",
    "    sO = 1/(1+np.exp(-Z))\n",
    "    \n",
    "    \n",
    "    return sO\n",
    "\n",
    "def relu(Z):\n",
    "    #Implement the RELU function#\n",
    "    \n",
    "    rO = np.maximum(0,Z)\n",
    "     \n",
    "    return rO\n",
    "\n",
    "def softmax(Z):\n",
    "    # Z is numpy array of shape (n, m) where n is number of neurons in the layer and m is the number of samples \n",
    "    # softmax_memory is stored as it is used later on in backpropagation\n",
    "   \n",
    "    Z_exp = np.exp(Z - np.max(Z)) # np.exp(Z - np.max(Z))\n",
    "\n",
    "    Z_sum = np.sum(Z_exp,axis = 0, keepdims = True)\n",
    "    \n",
    "    smo = Z_exp/Z_sum \n",
    "   \n",
    "    \n",
    "    return smo\n",
    "\n",
    "def relu_backward(dA, rel):\n",
    "    #Implement the backward propagation for a single RELU unit.#\n",
    "    \n",
    "    Z = rel\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, sig):\n",
    "    #Implement the backward propagation for a single SIGMOID unit#\n",
    "    \n",
    "    \n",
    "    Z = sig\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "   \n",
    "    \n",
    "    return dZ\n"
   ]
  },
